<!DOCTYPE html>
<html lang="en">

<head>
  <title>Blog | Fritz Manambe</title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Fritz Elbert Christopel Manambe">
  <link rel="stylesheet" href="style.css">
  <!--
    <script src="script.js"></script>
  -->
</head>

<body>
  <div class="container">
    <header>
      <div class="nav-bar">
        <div class="nav-bar-left">
          <!--
            <span style="color: white;">Logo</span>
            -->
        </div>
        <div class="menu">
          <nav>
            <ul>
              <li><a href="index.html">Home</a></li>
              <li><a href="gallery.html">Gallery</a></li>
              <li><a href="blog.html">Blog</a></li>
              <li><a href="contact.html">Contact</a></li>
            </ul>
          </nav>
        </div>
      </div>
    </header>
    
    <div class="main-content">
      <h1 align="center">Blog</h1>
    
      <section>
        <article>
          <article class="article">
            <h1>A first-ever complete map for elastic strain engineering</h1>
            <div src="images\Blog\MIT-phonon-stability-boundary_article1.jpg" alt="strain-function-graph">
            <p>Without a map, it can be just about impossible to know not just where you are, but where you're going, and
              that's
              especially true when it comes to materials properties.
              For decades, scientists have understood that while bulk materials behave in certain ways, those rules can
              break down for
              materials at the micro- and nano-scales, and often in surprising ways. One of those surprises was the finding
              that, for
              some materials, applying even modest strains — a concept known as elastic strain engineering — on materials
              can
              dramatically improve certain properties, provided those strains stay elastic and do not relax away by
              plasticity,
              fracture, or phase transformations. Micro- and nano-scale materials are especially good at holding applied
              strains in
              the elastic form.</p>
            <a href="https://news.mit.edu/2024/first-ever-complete-map-elastic-strain-engineering-0329">read more</a>
          </div>
        </article>
        <div>
          <div class="article">
            <h1>Kolmogorov-Arnold Networks (KANs): A New Era of Interpretability and Accuracy in Deep Learning</h1>
            <img src="images\Blog\Kolmogorov-Arnold--Networks_article2.png" alt="strain-function-graph">
            <p>Multi-layer perceptrons (MLPs), or fully-connected feedforward neural networks, are fundamental in deep
              learning,
              serving as default models for approximating nonlinear functions. Despite their importance affirmed by the
              universal
              approximation theorem, they possess drawbacks. In applications like transformers, MLPs often monopolize
              parameters and
              lack interpretability compared to attention layers. While exploring alternatives, such as the
              Kolmogorov-Arnold
              representation theorem, research has primarily focused on traditional depth-2 width-(2n+1) architectures,
              neglecting
              modern training techniques like backpropagation. Thus, while MLPs remain crucial, there’s ongoing exploration
              for more
              effective nonlinear regressors in neural network design.</p>
            <a
              href="https://www.marktechpost.com/2024/05/02/kolmogorov-arnold-networks-kans-a-new-era-of-interpretability-and-accuracy-in-deep-learning/">read
              more</a>
          </div>
          </div>
          <article>
            <div class="article">
              <h1>Huawei AI Introduces 'Kangaroo': A Novel Self-Speculative Decoding Framework Tailored for Accelerating the
                Inference of Large Language Models</h1>
              <img src="images\Blog\Kangaroo-framework_article3.png" alt="strain-function-graph">
              <p>The development of natural language processing has been significantly propelled by the advancements in
                large language
                models (LLMs). These models have showcased remarkable performance in tasks like translation, question
                answering, and
                text summarization, proving their efficiency in generating high-quality text. However, despite their
                effectiveness, one
                major limitation remains their slow inference speed, which hinders their use in real-time applications. This
                challenge
                predominantly arises from the memory bandwidth bottleneck rather than a lack of computational power, leading
                to
                researchers seeking innovative ways to speed up their inference process.</p>
              <a
                href="https://www.marktechpost.com/2024/05/02/huawei-ai-introduces-kangaroo-a-novel-self-speculative-decoding-framework-tailored-for-accelerating-the-inference-of-large-language-models/">read
                more</a>
            </div>
          </article>
      </section>
    </div>
  </div>

  <footer>
    <div class="footer">
      &copy; 2024 Fritz Manambe. All rights reserved.
    </div>
  </footer>
</body>

</html>
